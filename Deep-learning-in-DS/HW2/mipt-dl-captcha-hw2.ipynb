{"cells":[{"cell_type":"code","execution_count":39,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-05-26T23:18:30.435667Z","iopub.status.busy":"2024-05-26T23:18:30.435260Z","iopub.status.idle":"2024-05-26T23:18:30.448203Z","shell.execute_reply":"2024-05-26T23:18:30.446796Z","shell.execute_reply.started":"2024-05-26T23:18:30.435640Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/captcha/mds-misis-dl-captchan/sample_submission.csv\n","/kaggle/input/captcha/mds-misis-dl-captchan/images.npy\n","/kaggle/input/captcha/mds-misis-dl-captchan/labels.npy\n","/kaggle/input/captcha/mds-misis-dl-captchan/images_sub.npy\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","metadata":{},"source":["## Описание\n","\n","В этом соревновании вам предлагается задача из области компьютерного зрения – распознавание букв английского алфавита на искаженных и зашумленных изображениях.\n","\n","Данные для обучения содержатся в двух файлах: images.npy и labels.npy. Это формат numpy-массивов.\n","\n","Всего доступно 20 тысяч размеченных изображений размером 48x48 с 3 цветовыми каналами (RGB), поэтому массив images имеет размер (20000, 48, 48, 3). В массиве labels содержатся ответы к тренировочному набору изображений. В английском алфавите 26 букв: 0-й класс соответствует букве А и так далее по алфавиту, 25-й класс — буква Z.\n","\n","Ваша задача — обучить нейронную сеть и с ее помощью предсказать метки классов для изображений из файла images_sub.npy, в нем 50 тысяч изображений. Посмотрите на структуру файла sample_submission.csv — он не содержит полезных данных, а лишь описывает формат, в котором вы загружаете ваши предсказания на сайт. Создайте из ваших предсказаний такой же файл и загрузите в качестве вашего ответа (сабмита). Вы можете делать до 20 сабмитов в сутки.\n","Метрика лидерборда — accuracy, то есть доля правильно распознанных изображений.\n","\n","Задача будет считаться решенной, если в Public Leaderboard вы наберете score, который будет равен или больше 0.82.\n","\n","## Описание данных\n","\n","- images.npy - изображения для обучения\n","- labels.npy - метки для обучения\n","- sample_submission.csv - формат файла для сабмита\n","- images_sub.npy - изображения для сабмита"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T23:18:34.375817Z","iopub.status.busy":"2024-05-26T23:18:34.375407Z","iopub.status.idle":"2024-05-26T23:18:34.436074Z","shell.execute_reply":"2024-05-26T23:18:34.434898Z","shell.execute_reply.started":"2024-05-26T23:18:34.375788Z"},"trusted":true},"outputs":[],"source":["# Data loading\n","import numpy as np\n","\n","images = np.load('/kaggle/input/captcha/mds-misis-dl-captchan/images.npy')\n","labels = np.load('/kaggle/input/captcha/mds-misis-dl-captchan/labels.npy')"]},{"cell_type":"markdown","metadata":{},"source":["## Data visualization"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import string\n","import matplotlib.pyplot as plt\n","\n","letters = string.ascii_uppercase\n","alphabet_list = list(letters)\n","n_classes = len(letters)\n","\n","print(\"Number of classes: \", n_classes)\n","print(letters)"]},{"cell_type":"markdown","metadata":{},"source":["## Data Loader"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T23:18:37.194426Z","iopub.status.busy":"2024-05-26T23:18:37.193678Z","iopub.status.idle":"2024-05-26T23:18:37.206133Z","shell.execute_reply":"2024-05-26T23:18:37.205079Z","shell.execute_reply.started":"2024-05-26T23:18:37.194381Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torchvision\n","import numpy as np\n","\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import datasets, transforms\n","\n","class NpyImagesDataset(Dataset):\n","    def __init__(self, images_npy, labels_npy='', transform=None):\n","        \"\"\"\n","        Конструктор для класса NpyImagesDataset.\n","\n","        :param images_npy: Путь к .npy файлу с изображениями\n","        :param labels_npy: Путь к .npy файлу с метками (опционально)\n","        :param transform: Трансформации, которые нужно применить к изображениям (опционально)\n","        \"\"\"\n","        self.transform = transform\n","        self.images = np.load(images_npy)      # Loading images from a .npy file\n","        \n","        if labels_npy:\n","            self.labels = np.load(labels_npy)  # Load tags from the .npy file if the path is specified\n","        else:\n","            self.labels = None\n","  \n","    def __len__(self):\n","        \"\"\"\n","        Возвращает количество изображений в наборе данных.\n","\n","        :return: Количество изображений\n","        \"\"\"\n","        return len(self.images)   \n","    \n","    def get_label(self, index):\n","        \"\"\"\n","        Возвращает метку для указанного индекса.\n","\n","        :param index: Индекс изображения\n","        :return: Метка изображения или 0, если метки не загружены\n","        \"\"\"\n","        if self.labels is not None:\n","            return self.labels[index]\n","        return 0\n","\n","    def __getitem__(self, index):\n","        \"\"\"\n","        Возвращает изображение и его метку по указанному индексу.\n","\n","        :param index: Индекс изображения\n","        :return: Кортеж (изображение, метка)\n","        \"\"\"\n","        image = self.images[index]\n","        if self.transform is not None:\n","            image = self.transform(image)    # Apply transformations if specified\n","        return image, self.get_label(index)  # Returning the image and its label"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T23:18:39.322413Z","iopub.status.busy":"2024-05-26T23:18:39.322034Z","iopub.status.idle":"2024-05-26T23:18:39.398734Z","shell.execute_reply":"2024-05-26T23:18:39.397548Z","shell.execute_reply.started":"2024-05-26T23:18:39.322384Z"},"trusted":true},"outputs":[],"source":["import torchvision.transforms as transforms\n","import numpy as np\n","\n","alex_net_image_size = 227\n","\n","class PerImageNormalization(object):\n","    def __call__(self, tensor_image):\n","        \"\"\"\n","        Нормализация каждого изображения по отдельности.\n","\n","        :param tensor_image: Тензор изображения\n","        :return: Нормализованный тензор\n","        \"\"\"\n","        mean, std = tensor_image.mean([1, 2]), tensor_image.std([1, 2]) # Calculate the average and standard deviation by channel\n","        normalize = transforms.Normalize(mean=mean, std=std)            # Create a Normalize object with the calculated values\n","        return normalize(tensor_image)                                  # Applying normalization to the image\n","\n","    def __repr__(self):\n","        \"\"\"\n","        Возвращает строковое представление класса.\n","\n","        :return: Имя класса\n","        \"\"\"\n","        return self.__class__.__name__ + '()'\n","\n","# Determining the sequence of image transformations\n","image_transformation = transforms.Compose([\n","    transforms.ToPILImage(),                                        # Converting a Tensor or Array to a PIL Image\n","    transforms.Resize((alex_net_image_size, alex_net_image_size)),  # Resizing an Image\n","    transforms.ToTensor(),                                          # Converting PIL Image back to tensor\n","    PerImageNormalization()                                         # Applying normalization to each image\n","])\n","\n","# Creating a dataset using specified transformations\n","train_dataset = NpyImagesDataset('/kaggle/input/captcha/mds-misis-dl-captchan/images.npy', '/kaggle/input/captcha/mds-misis-dl-captchan/labels.npy', image_transformation)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T21:35:53.986258Z","iopub.status.busy":"2024-05-26T21:35:53.985845Z","iopub.status.idle":"2024-05-26T21:35:54.019497Z","shell.execute_reply":"2024-05-26T21:35:54.018299Z","shell.execute_reply.started":"2024-05-26T21:35:53.986227Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import random_split\n","\n","validation_set_size = int(0.2 * len(train_dataset))\n","train_set_size = len(train_dataset) - validation_set_size\n","\n","torch.manual_seed(42)\n","train_subset, validation_subset = random_split(train_dataset, [train_set_size, validation_set_size])"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T21:35:57.258013Z","iopub.status.busy":"2024-05-26T21:35:57.257552Z","iopub.status.idle":"2024-05-26T21:35:57.603237Z","shell.execute_reply":"2024-05-26T21:35:57.601983Z","shell.execute_reply.started":"2024-05-26T21:35:57.257978Z"},"trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["_ = plt.hist(train_subset.dataset.labels, bins=list(range(0, n_classes)))"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T21:35:59.610307Z","iopub.status.busy":"2024-05-26T21:35:59.609801Z","iopub.status.idle":"2024-05-26T21:35:59.617641Z","shell.execute_reply":"2024-05-26T21:35:59.616175Z","shell.execute_reply.started":"2024-05-26T21:35:59.610263Z"},"trusted":true},"outputs":[],"source":["BATCH_SIZE = 64\n","\n","train_dl = DataLoader(train_subset, batch_size = BATCH_SIZE, shuffle = True)\n","val_dl   = DataLoader(validation_subset, batch_size = BATCH_SIZE, shuffle = False)"]},{"cell_type":"markdown","metadata":{},"source":["## Model"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T23:19:03.739431Z","iopub.status.busy":"2024-05-26T23:19:03.738999Z","iopub.status.idle":"2024-05-26T23:19:03.758738Z","shell.execute_reply":"2024-05-26T23:19:03.757379Z","shell.execute_reply.started":"2024-05-26T23:19:03.739398Z"},"trusted":true},"outputs":[],"source":["from torch.nn import Linear, ReLU, CrossEntropyLoss, Conv2d, MaxPool2d, Module, BatchNorm2d\n","from torch.optim import Adam\n","import torch.nn.functional as F\n","\n","class AlexCaptchaNet(Module):   \n","    def __init__(self):\n","        \"\"\"\n","        Конструктор для создания слоев модели.\n","        \"\"\"\n","        super(AlexCaptchaNet, self).__init__()\n","        \n","        # First convolutional layer\n","        self.conv1 = Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4, padding=0)\n","        self.batchnorm1 = BatchNorm2d(96)\n","        self.maxpool = MaxPool2d(kernel_size=3, stride=2)\n","        \n","        # Second convolutional layer\n","        self.conv2 = Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2)\n","        self.batchnorm2 = BatchNorm2d(256)\n","        \n","        # 3rd convolutional layer\n","        self.conv3 = Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1)\n","        self.batchnorm3 = BatchNorm2d(384)\n","        \n","        # 4th сверточный слой\n","        self.conv4 = Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1)\n","        self.batchnorm4 = BatchNorm2d(384)\n","        \n","        # 5th сверточный слой\n","        self.conv5 = Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1)\n","        self.batchnorm5 = BatchNorm2d(256)\n","        \n","        # Fully connected layers\n","        self.fc1 = Linear(in_features=9216, out_features=4096)\n","        self.fc2 = Linear(in_features=4096, out_features=4096)\n","        self.fc3 = Linear(in_features=4096, out_features=n_classes)  # n_classes = 26\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Прямое распространение (forward pass).\n","        \n","        :param x: Входной тензор\n","        :return: Выходной тензор\n","        \"\"\"\n","        x = F.relu(self.conv1(x.float()))  # Applying the first convolutional layer and ReLU\n","        x = self.batchnorm1(x)             # Applying Batch Normalization\n","        x = self.maxpool(x)                # Application of Max Pooling\n","        \n","        x = F.relu(self.conv2(x))\n","        x = self.batchnorm2(x)\n","        x = self.maxpool(x)\n","        \n","        x = F.relu(self.conv3(x))\n","        x = self.batchnorm3(x)\n","        \n","        x = F.relu(self.conv4(x))\n","        x = self.batchnorm4(x)\n","        \n","        x = F.relu(self.conv5(x))\n","        x = self.batchnorm5(x)\n","        x = self.maxpool(x)\n","        \n","        x = x.reshape(x.shape[0], -1)      # Tensor alignment\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","\n","        return x"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T21:36:03.397497Z","iopub.status.busy":"2024-05-26T21:36:03.397122Z","iopub.status.idle":"2024-05-26T21:36:04.139275Z","shell.execute_reply":"2024-05-26T21:36:04.138171Z","shell.execute_reply.started":"2024-05-26T21:36:03.397471Z"},"trusted":true},"outputs":[],"source":["model = AlexCaptchaNet()"]},{"cell_type":"markdown","metadata":{},"source":["## Predict"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T21:36:09.545177Z","iopub.status.busy":"2024-05-26T21:36:09.544738Z","iopub.status.idle":"2024-05-26T21:36:09.550180Z","shell.execute_reply":"2024-05-26T21:36:09.549225Z","shell.execute_reply.started":"2024-05-26T21:36:09.545143Z"},"trusted":true},"outputs":[],"source":["LEARNING_RATE = 1e-4\n","EPOCH_NUM = 1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T23:19:06.883633Z","iopub.status.busy":"2024-05-26T23:19:06.883246Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Loss in epoch 0 :::: 0.40191447561979293\n","Got 3364 / 4000 with accuracy 84.10\n"]}],"source":["# Send the model to the device for training - CPU\n","device='cpu'\n","model = model.to(device='cpu')\n","\n","# Set the loss function and optimizer\n","learning_rate = LEARNING_RATE\n","criterion = CrossEntropyLoss()                          # Cross-entropy loss function\n","optimizer = Adam(model.parameters(), lr=learning_rate)  # Adam Optimizer\n","\n","# Learning cycle\n","for epoch in range(EPOCH_NUM):\n","    loss_ep = 0\n","    \n","    # Training on the training data set\n","    for batch_idx, (data, targets) in enumerate(train_dl):\n","        data = data.to(device='cpu')\n","        targets = targets.to(device='cpu')\n","        \n","        optimizer.zero_grad()\n","        scores = model(data)               # Forward pass\n","        loss = criterion(scores, targets)  # Calculating losses\n","        loss.backward()                    # Backward pass\n","        optimizer.step()                   # Update model parameters\n","        \n","        loss_ep += loss.item()\n","        \n","    # Display the average losses per epoch\n","    print(f\"Loss in epoch {epoch} :: {loss_ep / len(train_dl)}\")\n","\n","    # Model evaluation on a validation dataset\n","    with torch.no_grad():\n","        num_correct = 0\n","        num_samples = 0\n","        \n","        for batch_idx, (data, targets) in enumerate(val_dl):\n","            data = data.to(device=device)\n","            targets = targets.to(device=device)\n","            \n","            scores = model(data)\n","            _, predictions = scores.max(1)\n","            num_correct += (predictions == targets).sum()  # Count the number of correct predictions\n","            num_samples += predictions.size(0)             # Count the number of samples\n","        \n","        # Display the accuracy of the model\n","        print(\n","            f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct) / float(num_samples) * 100:.2f}\"\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["torch.save(model.state_dict(), './model.pth')"]},{"cell_type":"markdown","metadata":{},"source":["## Test before submission"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.load_state_dict(torch.load('model.pth'))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["dataset_for_final = NpyImagesDataset('/kaggle/input/captcha/mds-misis-dl-captchan/images_sub.npy', '', image_transformation)\n","submission_dl = DataLoader(dataset_for_final, batch_size = BATCH_SIZE, shuffle = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["submission_resuls = []\n","\n","for batch_idx, (data, targets) in enumerate(submission_dl):\n","    scores = model(data.cpu())\n","    softmax = torch.exp(scores).cpu()\n","    prob = list(softmax.detach().numpy())\n","    predictions = np.argmax(prob, axis=1)\n","    submission_resuls.append(predictions)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import pandas as pd \n","\n","# Write data to submission file\n","sample_submission = pd.read_csv('/kaggle/input/captcha/mds-misis-dl-captchan/sample_submission.csv')\n","sample_submission.head()\n","\n","sample_submission['Category'] = np.concatenate(submission_resuls)\n","sample_submission.to_csv('captcha_submission.csv', index=False)\n","sample_submission.head(10)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":8432179,"sourceId":77379,"sourceType":"competition"},{"datasetId":5090551,"sourceId":8524882,"sourceType":"datasetVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
